{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gRPC Client Test\n",
    "\n",
    "This notebook tests the gRPC rendering server by:\n",
    "1. Loading camera data from USDZ file\n",
    "2. Getting the first camera pose\n",
    "3. Calling the gRPC API to render\n",
    "4. Displaying the result with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "USDZ_PATH = Path(\n",
    "    \"data/sample_set/25.07_release/Batch0001/0d79a6a0-4aa7-4eb1-aea1-31fd55bd71d7/0d79a6a0-4aa7-4eb1-aea1-31fd55bd71d7.usdz\"\n",
    ")  # TODO: Update this path\n",
    "SERVER_HOST = \"127.0.0.1\"\n",
    "SERVER_PORT = 50051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gRPC dependencies\n",
    "# Import gRPC protocol definitions\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import grpc\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"grpc\"))\n",
    "\n",
    "import simple_nurec_grpc\n",
    "from simple_nurec_grpc import render_pb2, render_pb2_grpc\n",
    "\n",
    "print(\"gRPC protocol loaded successfully\")\n",
    "print(f\"Available modules: {simple_nurec_grpc.__all__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Camera Data from USDZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_nurec_viewer.export.camera import compute_camera_pose_NRE, get_camera_intrinsics, interpolate_rig_pose\n",
    "from simple_nurec_viewer.export.loader import load_camera_data\n",
    "\n",
    "# Load camera data\n",
    "camera_calibrations, rig_trajectories, world_to_nre = load_camera_data(USDZ_PATH)\n",
    "\n",
    "print(f\"Loaded {len(camera_calibrations)} camera calibrations\")\n",
    "print(f\"Rig trajectory sequence: {rig_trajectories.sequence_id}\")\n",
    "print(f\"Number of rig poses: {len(rig_trajectories.T_rig_worlds)}\")\n",
    "\n",
    "# List all cameras\n",
    "camera_names = list(set(calib.logical_sensor_name for calib in camera_calibrations.values()))\n",
    "print(f\"\\nAvailable cameras: {camera_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get First Camera Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first camera (prefer front_wide if available)\n",
    "camera_name = \"camera_front_wide_120fov\"\n",
    "\n",
    "# Find the calibration key for this camera\n",
    "calib_key = None\n",
    "for key, calib in camera_calibrations.items():\n",
    "    if calib.logical_sensor_name == camera_name:\n",
    "        calib_key = key\n",
    "        break\n",
    "\n",
    "if calib_key is None:\n",
    "    raise ValueError(f\"Camera {camera_name} not found in calibrations\")\n",
    "\n",
    "calib = camera_calibrations[calib_key]\n",
    "\n",
    "# Get first frame timestamp\n",
    "if calib_key not in rig_trajectories.cameras_frame_timestamps_us:\n",
    "    raise ValueError(f\"No timestamps found for camera {camera_name}\")\n",
    "\n",
    "timestamps = rig_trajectories.cameras_frame_timestamps_us[calib_key]\n",
    "first_timestamp_us = timestamps[0][0]  # (start_us, end_us)\n",
    "\n",
    "print(f\"Selected camera: {camera_name}\")\n",
    "print(f\"Calibration key: {calib_key}\")\n",
    "print(f\"Camera model: {calib.camera_model_type}\")\n",
    "print(f\"Resolution: {calib.resolution}\")\n",
    "print(f\"Principal point: {calib.principal_point}\")\n",
    "print(f\"First timestamp: {first_timestamp_us} us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate rig pose to camera timestamp\n",
    "T_rig_world = interpolate_rig_pose(\n",
    "    first_timestamp_us,\n",
    "    rig_trajectories.T_rig_world_timestamps_us,\n",
    "    rig_trajectories.T_rig_worlds,\n",
    ")\n",
    "\n",
    "# Compute camera pose in NRE coordinates\n",
    "T_camera_NRE = compute_camera_pose_NRE(\n",
    "    calib.T_sensor_rig,\n",
    "    T_rig_world,\n",
    "    world_to_nre,\n",
    ")\n",
    "\n",
    "# Get camera intrinsics\n",
    "if calib.camera_model_type == \"ftheta\":\n",
    "    K = get_camera_intrinsics(\n",
    "        calib.camera_model_type,\n",
    "        calib.resolution,\n",
    "        calib.principal_point,\n",
    "        max_angle=calib.max_angle,\n",
    "    )\n",
    "elif calib.camera_model_type == \"pinhole\":\n",
    "    focal_length = getattr(calib, \"focal_length\", calib.resolution[0] * 0.8)\n",
    "    K = get_camera_intrinsics(\n",
    "        calib.camera_model_type,\n",
    "        calib.resolution,\n",
    "        calib.principal_point,\n",
    "        focal_length=focal_length,\n",
    "    )\n",
    "\n",
    "print(f\"Camera position in NRE: {T_camera_NRE[:3, 3]}\")\n",
    "print(f\"\\nCamera intrinsics K:\\n{K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build gRPC Render Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build view matrix for gRPC rendering\n",
    "# T_camera_NRE transforms from camera to NRE\n",
    "# The server expects us to send T_camera_NRE directly, then it will compute viewmat = inv(T_camera_NRE)\n",
    "camera_to_world_3x4 = T_camera_NRE[:3, :4].flatten().tolist()\n",
    "\n",
    "# Extract intrinsics\n",
    "fx, fy = K[0, 0], K[1, 1]\n",
    "cx, cy = K[0, 2], K[1, 2]\n",
    "width, height = calib.resolution\n",
    "\n",
    "# Convert timestamp to seconds\n",
    "timestamp_s = first_timestamp_us / 1e6\n",
    "\n",
    "# Create render request\n",
    "request = render_pb2.RenderRequest()\n",
    "request.camera.camera_to_world.extend(camera_to_world_3x4)\n",
    "request.camera.fx = fx\n",
    "request.camera.fy = fy\n",
    "request.camera.cx = cx\n",
    "request.camera.cy = cy\n",
    "request.camera.width = width\n",
    "request.camera.height = height\n",
    "request.camera.camera_model = calib.camera_model_type\n",
    "request.camera.time = timestamp_s\n",
    "\n",
    "# Add FTheta distortion parameters if applicable\n",
    "if calib.camera_model_type == \"ftheta\":\n",
    "    ftheta_params = request.camera.ftheta_params\n",
    "    ftheta_params.reference_poly = calib.reference_poly\n",
    "    ftheta_params.pixeldist_to_angle_poly.extend(calib.pixeldist_to_angle_poly)\n",
    "    ftheta_params.angle_to_pixeldist_poly.extend(calib.angle_to_pixeldist_poly)\n",
    "    ftheta_params.max_angle = calib.max_angle\n",
    "    # Set linear_cde (C, D, E distortion coefficients)\n",
    "    if hasattr(calib, \"linear_cde\") and calib.linear_cde is not None:\n",
    "        ftheta_params.linear_cde.extend(calib.linear_cde)\n",
    "\n",
    "print(\"\\nRender request created:\")\n",
    "print(f\"  Camera: {camera_name}\")\n",
    "print(f\"  Model: {calib.camera_model_type}\")\n",
    "print(f\"  Resolution: {width}x{height}\")\n",
    "print(f\"  Intrinsics: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}\")\n",
    "print(f\"  Timestamp: {timestamp_s:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to gRPC Server and Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gRPC channel with increased message size (256 MB for high-res images)\n",
    "max_message_length = 256 * 1024 * 1024  # 256 MB\n",
    "channel_options = [\n",
    "    (\"grpc.max_send_message_length\", max_message_length),\n",
    "    (\"grpc.max_receive_message_length\", max_message_length),\n",
    "]\n",
    "channel = grpc.insecure_channel(f\"{SERVER_HOST}:{SERVER_PORT}\", options=channel_options)\n",
    "\n",
    "# Create stub\n",
    "stub = render_pb2_grpc.RenderServiceStub(channel)\n",
    "\n",
    "print(f\"Connected to gRPC server at {SERVER_HOST}:{SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send render request\n",
    "print(f\"Sending render request for {camera_name}...\")\n",
    "\n",
    "try:\n",
    "    response = stub.Render(request)\n",
    "\n",
    "    if response.success:\n",
    "        print(\"Render successful!\")\n",
    "        print(f\"  Resolution: {response.rgb_image.width}x{response.rgb_image.height}\")\n",
    "        print(f\"  Render time: {response.render_time_ms:.2f}ms\")\n",
    "        print(f\"  Data size: {len(response.rgb_image.rgb_data)} bytes\")\n",
    "    else:\n",
    "        print(f\"Render failed: {response.error_message}\")\n",
    "except grpc.RpcError as e:\n",
    "    print(f\"gRPC error: {e.code()}\")\n",
    "    print(f\"Details: {e.details()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Rendered Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.success:\n",
    "    # Convert bytes to numpy array\n",
    "    rgb_data = np.frombuffer(response.rgb_image.rgb_data, dtype=np.uint8)\n",
    "    image = rgb_data.reshape(response.rgb_image.height, response.rgb_image.width, 3)\n",
    "\n",
    "    # Display image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{camera_name} - {calib.camera_model_type} - t={timestamp_s:.3f}s\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print image info\n",
    "    print(f\"\\nImage shape: {image.shape}\")\n",
    "    print(f\"Data type: {image.dtype}\")\n",
    "    print(f\"Value range: [{image.min()}, {image.max()}]\")\n",
    "else:\n",
    "    print(\"No image to display (render failed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close channel\n",
    "channel.close()\n",
    "print(\"Channel closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nurec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
